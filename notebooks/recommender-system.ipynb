{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  y\n"
     ]
    }
   ],
   "source": [
    "# Clear all variables and conserve memory\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 100\n",
    "\n",
    "# Recommender systems\n",
    "import funk_svd\n",
    "from funk_svd.dataset import fetch_ml_ratings\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import surprise as sp\n",
    "\n",
    "# Other\n",
    "import numba as nb\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from sys import getsizeof\n",
    "\n",
    "# Reload imported code\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Custom modules\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAL Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "# user_df = pd.read_csv('../data/raw/users_cleaned.csv')\n",
    "# anime_df = pd.read_csv('../data/raw/anime_cleaned.csv')\n",
    "user_animelist_df = pd.read_csv('../data/raw/animelists_cleaned.csv')\n",
    "\n",
    "user_animelist_df = user_animelist_df[['username', 'anime_id', 'my_score']]\n",
    "user_animelist_df.rename(columns = {'username': 'u_id', 'anime_id': 'i_id', 'my_score': 'rating'}, inplace = True)\n",
    "\n",
    "# Split data\n",
    "train = user_animelist_df.sample(frac=0.8, random_state=7)\n",
    "val = user_animelist_df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
    "test = user_animelist_df.drop(train.index.tolist()).drop(val.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by comparing Funk SVD and Surprise libraries to see how they compare with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funk SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/100  | val_loss: 12.08 - val_rmse: 3.48 - val_mae: 3.11 - took 4.6 sec\n",
      "Epoch 2/100  | val_loss: 10.88 - val_rmse: 3.30 - val_mae: 2.85 - took 3.2 sec\n",
      "Epoch 3/100  | val_loss: 10.23 - val_rmse: 3.20 - val_mae: 2.66 - took 3.2 sec\n",
      "Epoch 4/100  | val_loss: 9.82 - val_rmse: 3.13 - val_mae: 2.56 - took 3.0 sec\n",
      "Epoch 5/100  | val_loss: 9.46 - val_rmse: 3.08 - val_mae: 2.47 - took 3.1 sec\n",
      "Epoch 6/100  | val_loss: 9.18 - val_rmse: 3.03 - val_mae: 2.40 - took 3.3 sec\n",
      "Epoch 7/100  | val_loss: 9.00 - val_rmse: 3.00 - val_mae: 2.36 - took 3.2 sec\n",
      "Epoch 8/100  | val_loss: 8.87 - val_rmse: 2.98 - val_mae: 2.32 - took 3.1 sec\n",
      "Epoch 9/100  | val_loss: 8.79 - val_rmse: 2.96 - val_mae: 2.30 - took 3.1 sec\n",
      "Epoch 10/100 | val_loss: 8.72 - val_rmse: 2.95 - val_mae: 2.28 - took 3.1 sec\n",
      "Epoch 11/100 | val_loss: 8.68 - val_rmse: 2.95 - val_mae: 2.27 - took 3.1 sec\n",
      "Epoch 12/100 | val_loss: 8.64 - val_rmse: 2.94 - val_mae: 2.26 - took 3.1 sec\n",
      "Epoch 13/100 | val_loss: 8.62 - val_rmse: 2.94 - val_mae: 2.25 - took 3.1 sec\n",
      "Epoch 14/100 | val_loss: 8.60 - val_rmse: 2.93 - val_mae: 2.25 - took 3.1 sec\n",
      "Epoch 15/100 | val_loss: 8.58 - val_rmse: 2.93 - val_mae: 2.24 - took 3.1 sec\n",
      "Epoch 16/100 | val_loss: 8.56 - val_rmse: 2.93 - val_mae: 2.24 - took 3.1 sec\n",
      "Epoch 17/100 | val_loss: 8.55 - val_rmse: 2.92 - val_mae: 2.23 - took 3.4 sec\n",
      "Epoch 18/100 | val_loss: 8.55 - val_rmse: 2.92 - val_mae: 2.23 - took 3.1 sec\n",
      "Epoch 19/100 | val_loss: 8.54 - val_rmse: 2.92 - val_mae: 2.23 - took 3.2 sec\n",
      "Epoch 20/100 | val_loss: 8.53 - val_rmse: 2.92 - val_mae: 2.23 - took 3.1 sec\n",
      "Epoch 21/100 | val_loss: 8.53 - val_rmse: 2.92 - val_mae: 2.22 - took 3.2 sec\n",
      "\n",
      "Training took 1 min and 26 sec\n",
      "Test MSE: 10.90\n",
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "svd = funk_svd.SVD(learning_rate=0.001, regularization=0.005, n_epochs=100,\n",
    "          n_factors=15, min_rating=1, max_rating=5)\n",
    "\n",
    "svd.fit(X=train, X_val=val, early_stopping=True, shuffle=False)\n",
    "\n",
    "pred = svd.predict(test)\n",
    "mae = mean_squared_error(test[\"rating\"], pred)\n",
    "\n",
    "print(f'Test MSE: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 50min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1bfe3c06108>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "surprise_svd = sp.SVD(lr_all=0.001, reg_all=0.005, n_epochs=100,\n",
    "          n_factors=15)\n",
    "\n",
    "reader = sp.Reader()\n",
    "\n",
    "data_train = sp.Dataset.load_from_df(train[['u_id', 'i_id', 'rating']], reader = reader).build_full_trainset()\n",
    "data_test = sp.Dataset.load_from_df(test[['u_id', 'i_id', 'rating']], reader = reader).build_full_trainset().build_testset()\n",
    "surprise_svd.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.2992\n",
      "Wall time: 1min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.2991533921074048"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Get predictions and calculate test RMSE\n",
    "\n",
    "sp_predictions = surprise_svd.test(data_test)\n",
    "sp.accuracy.rmse(sp_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "\n",
    "Overall they produce similar and decent results, however the Funk SVD package is much faster in speed. By looking at the github repo it seems to be the difference between Numba and Cython. The downside to this is that Funk SVD only provides and SVD implementation and none others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimenting algorithms with movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_ml_ratings(variant = '1m')\n",
    "\n",
    "# Prepare data\n",
    "train = df.sample(frac=0.8, random_state=7)\n",
    "val = df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
    "test = df.drop(train.index.tolist()).drop(val.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Model with global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 1.116911\n"
     ]
    }
   ],
   "source": [
    "global_mean = train['rating'].mean()\n",
    "pred = [global_mean for _ in range(test.shape[0])]\n",
    "\n",
    "rmse = mean_squared_error(test['rating'], pred, squared = False)\n",
    "\n",
    "print(f'\\nTest RMSE: {rmse:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model with biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = train['rating'].mean()\n",
    "\n",
    "user_biases = train.drop(['i_id'], axis=1).groupby('u_id').mean() - global_mean\n",
    "item_biases = train.drop(['u_id'], axis=1).groupby('i_id').mean() - global_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 0.938412\n"
     ]
    }
   ],
   "source": [
    "pred = pd.merge(test[['u_id', 'i_id']], user_biases, how = 'left', left_on = 'u_id', right_index = True)\n",
    "pred = pd.merge(pred, item_biases, how = 'left', left_on = 'i_id', right_index = True)\n",
    "pred.fillna(0, inplace=True)\n",
    "pred = pred['rating_x'] + pred['rating_y'] + global_mean\n",
    "\n",
    "rmse = mean_squared_error(test['rating'], pred, squared = False)\n",
    "\n",
    "print(f'\\nTest RMSE: {rmse:4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model with biases - SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 20  -  train_rmse: 6.196910058098994e-05\n",
      "Epoch  2 / 20  -  train_rmse: 3.0374388476043757e-06\n",
      "Epoch  3 / 20  -  train_rmse: 2.1143773117482846e-06\n",
      "Epoch  4 / 20  -  train_rmse: 9.998486170829027e-07\n",
      "Epoch  5 / 20  -  train_rmse: 4.164351069822115e-07\n",
      "Epoch  6 / 20  -  train_rmse: 1.3317714122277283e-07\n",
      "Epoch  7 / 20  -  train_rmse: 1.4631216438962827e-08\n",
      "Epoch  8 / 20  -  train_rmse: 1.0867114685708993e-08\n",
      "Epoch  9 / 20  -  train_rmse: 9.998871521273606e-08\n",
      "Epoch  10 / 20  -  train_rmse: 2.6577130552643495e-07\n",
      "Epoch  11 / 20  -  train_rmse: 4.920030231244285e-07\n",
      "Epoch  12 / 20  -  train_rmse: 7.624426932040988e-07\n",
      "Epoch  13 / 20  -  train_rmse: 1.061983624065085e-06\n",
      "Epoch  14 / 20  -  train_rmse: 1.3775795316492494e-06\n",
      "Epoch  15 / 20  -  train_rmse: 1.698652439713734e-06\n",
      "Epoch  16 / 20  -  train_rmse: 2.0170840514535404e-06\n",
      "Epoch  17 / 20  -  train_rmse: 2.326962516121101e-06\n",
      "Epoch  18 / 20  -  train_rmse: 2.6242243599428368e-06\n",
      "Epoch  19 / 20  -  train_rmse: 2.9062805812922113e-06\n",
      "Epoch  20 / 20  -  train_rmse: 3.1716742363164055e-06\n",
      "Wall time: 581 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaselineModel(lr=0.005, max_rating=5, min_rating=0, n_epochs=20, reg=0.005,\n",
       "              verbose=1)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "baseline_model = BaselineModel(n_epochs = 20, reg = 0.005)\n",
    "baseline_model.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 / 20  -  train_rmse: 0.06055417459619898\n",
      "Epoch  2 / 20  -  train_rmse: 0.012014171581518273\n",
      "Epoch  3 / 20  -  train_rmse: 0.0026045595794161954\n",
      "Epoch  4 / 20  -  train_rmse: 0.0007084621474111399\n",
      "Epoch  5 / 20  -  train_rmse: 0.0002769511151859069\n",
      "Epoch  6 / 20  -  train_rmse: 0.00015685467501911417\n",
      "Epoch  7 / 20  -  train_rmse: 0.00011258677295116814\n",
      "Epoch  8 / 20  -  train_rmse: 8.804513578312554e-05\n",
      "Epoch  9 / 20  -  train_rmse: 6.771620039728805e-05\n",
      "Epoch  10 / 20  -  train_rmse: 4.773444095496389e-05\n",
      "Epoch  11 / 20  -  train_rmse: 2.843289274759688e-05\n",
      "Epoch  12 / 20  -  train_rmse: 1.1980960720196331e-05\n",
      "Epoch  13 / 20  -  train_rmse: 1.624799926434436e-06\n",
      "Epoch  14 / 20  -  train_rmse: 1.5582180956251972e-06\n",
      "Epoch  15 / 20  -  train_rmse: 1.7073258054052865e-05\n",
      "Epoch  16 / 20  -  train_rmse: 5.485147537296227e-05\n",
      "Epoch  17 / 20  -  train_rmse: 0.0001233444015317176\n",
      "Epoch  18 / 20  -  train_rmse: 0.00023322848125212976\n",
      "Epoch  19 / 20  -  train_rmse: 0.00039793304116426405\n",
      "Epoch  20 / 20  -  train_rmse: 0.0006342412438748529\n",
      "\n",
      "Test RMSE: 0.9180\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "random.seed(2)\n",
    "np.random.seed(2)\n",
    "svd = SVD(n_epochs = 20, n_factors = 100, verbose = 1, lr = 0.001, reg = 0.005)\n",
    "svd.fit(train)\n",
    "\n",
    "pred, pred_possible = svd.predict(test)\n",
    "rmse = mean_squared_error(test['rating'], pred, squared = False)\n",
    "\n",
    "print(f'\\nTest RMSE: {rmse:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funk SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "\n",
      "Epoch 1/20  | took 0.2 sec\n",
      "Epoch 2/20  | took 0.3 sec\n",
      "Epoch 3/20  | took 0.3 sec\n",
      "Epoch 4/20  | took 0.3 sec\n",
      "Epoch 5/20  | took 0.3 sec\n",
      "Epoch 6/20  | took 0.3 sec\n",
      "Epoch 7/20  | took 0.3 sec\n",
      "Epoch 8/20  | took 0.3 sec\n",
      "Epoch 9/20  | took 0.3 sec\n",
      "Epoch 10/20 | took 0.3 sec\n",
      "Epoch 11/20 | took 0.3 sec\n",
      "Epoch 12/20 | took 0.3 sec\n",
      "Epoch 13/20 | took 0.3 sec\n",
      "Epoch 14/20 | took 0.3 sec\n",
      "Epoch 15/20 | took 0.3 sec\n",
      "Epoch 16/20 | took 0.2 sec\n",
      "Epoch 17/20 | took 0.3 sec\n",
      "Epoch 18/20 | took 0.3 sec\n",
      "Epoch 19/20 | took 0.2 sec\n",
      "Epoch 20/20 | took 0.2 sec\n",
      "\n",
      "Training took 6 sec\n",
      "Test RMSE: 0.92\n",
      "Wall time: 6.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(2)\n",
    "random.seed(2)\n",
    "\n",
    "train = df.sample(frac=0.8, random_state=7)\n",
    "val = df.drop(train.index.tolist()).sample(frac=0.5, random_state=8)\n",
    "test = df.drop(train.index.tolist()).drop(val.index.tolist())\n",
    "\n",
    "svd = funk_svd.SVD(learning_rate=0.001, regularization=0.005, n_epochs=20,\n",
    "          n_factors=100, min_rating=1, max_rating=5)\n",
    "\n",
    "svd.fit(X=train, X_val=val, early_stopping=False, shuffle=False)\n",
    "\n",
    "pred_funk = svd.predict(test)\n",
    "mae = mean_squared_error(test[\"rating\"], pred_funk, squared = False)\n",
    "\n",
    "print(f'Test RMSE: {mae:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movielens-100k dataset (download it if needed),\n",
    "data = sp.Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9265  0.9351  0.9324  0.9415  0.9408  0.9353  0.0056  \n",
      "MAE (testset)     0.7294  0.7344  0.7358  0.7421  0.7399  0.7363  0.0044  \n",
      "Fit time          4.16    4.19    4.22    4.25    4.20    4.20    0.03    \n",
      "Test time         0.13    0.45    0.11    0.11    0.11    0.18    0.13    \n",
      "Wall time: 22.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.92651162, 0.93507166, 0.93241232, 0.94154717, 0.94084358]),\n",
       " 'test_mae': array([0.72938989, 0.73444756, 0.73576219, 0.74210202, 0.73993852]),\n",
       " 'fit_time': (4.163815021514893,\n",
       "  4.187639236450195,\n",
       "  4.216679334640503,\n",
       "  4.247923374176025,\n",
       "  4.1983418464660645),\n",
       " 'test_time': (0.12666082382202148,\n",
       "  0.45206427574157715,\n",
       "  0.11275815963745117,\n",
       "  0.1120297908782959,\n",
       "  0.11228561401367188)}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = sp.SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "sp.model_selection.cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9169\n",
      "Wall time: 31.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9168845476049273"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "surprise_svd = sp.SVD(lr_all=0.001, reg_all=0.005, n_epochs=20,\n",
    "          n_factors=50)\n",
    "\n",
    "reader = sp.Reader()\n",
    "\n",
    "data_train = sp.Dataset.load_from_df(train[['u_id', 'i_id', 'rating']], reader = reader).build_full_trainset()\n",
    "data_test = sp.Dataset.load_from_df(test[['u_id', 'i_id', 'rating']], reader = reader).build_full_trainset().build_testset()\n",
    "surprise_svd.fit(data_train)\n",
    "\n",
    "pred = surprise_svd.test(data_test)\n",
    "sp.accuracy.rmse(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid=259, iid=200, r_ui=4.0, est=4.1670259763161255, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=357, r_ui=5.0, est=4.430772728105106, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=179, r_ui=4.0, est=4.20424005908081, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=1135, r_ui=5.0, est=3.231236971348656, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=15, r_ui=3.0, est=3.91758055378108, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=121, r_ui=3.0, est=3.590538369392122, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=294, r_ui=3.0, est=3.2821077351936805, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=748, r_ui=4.0, est=3.323876222072292, details={'was_impossible': False}),\n",
       " Prediction(uid=259, iid=147, r_ui=4.0, est=3.8508097317210708, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=696, r_ui=3.0, est=3.3294724032153775, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=473, r_ui=4.0, est=3.4560562799048773, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=290, r_ui=4.0, est=3.153519835790711, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=717, r_ui=3.0, est=2.8874506227253445, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=815, r_ui=3.0, est=3.3480640461758178, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=405, r_ui=5.0, est=3.274042812465488, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=924, r_ui=4.0, est=3.558746617931548, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=1094, r_ui=1.0, est=3.3761615671176846, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=1245, r_ui=4.0, est=3.437682521354039, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=411, r_ui=3.0, est=2.9552410061418772, details={'was_impossible': False}),\n",
       " Prediction(uid=851, iid=831, r_ui=5.0, est=2.636413116665653, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_svd.test(data_test)[:20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anime-recommender]",
   "language": "python",
   "name": "conda-env-anime-recommender-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
